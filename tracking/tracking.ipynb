{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_yolo_object_detection(image_to_process):\n",
    "    \"\"\"\n",
    "    Распознавание и определение координат объектов на изображении\n",
    "    :param image_to_process: исходное изображение\n",
    "    :return: изображение с отмеченными объектами и подписями к ним\n",
    "    \"\"\"\n",
    "\n",
    "    height, width, _ = image_to_process.shape\n",
    "    blob = cv2.dnn.blobFromImage(image_to_process, 1 / 255, (608, 608),\n",
    "                                 (0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(out_layers)\n",
    "    class_indexes, class_scores, boxes = ([] for i in range(3))\n",
    "    objects_count = 0\n",
    "\n",
    "    # Запуск поиска объектов на изображении\n",
    "    for out in outs:\n",
    "        for obj in out:\n",
    "            scores = obj[5:]\n",
    "            class_index = np.argmax(scores)\n",
    "            class_score = scores[class_index]\n",
    "            if class_score > 0:\n",
    "                center_x = int(obj[0] * width)\n",
    "                center_y = int(obj[1] * height)\n",
    "                obj_width = int(obj[2] * width)\n",
    "                obj_height = int(obj[3] * height)\n",
    "                box = [center_x - obj_width // 2, center_y - obj_height // 2,\n",
    "                       obj_width, obj_height]\n",
    "                boxes.append(box)\n",
    "                class_indexes.append(class_index)\n",
    "                class_scores.append(float(class_score))\n",
    "\n",
    "    # Выбор\n",
    "    chosen_boxes = cv2.dnn.NMSBoxes(boxes, class_scores, 0.0, 0.4)\n",
    "    for box_index in chosen_boxes:\n",
    "        box = boxes[box_index]\n",
    "        class_index = class_indexes[box_index]\n",
    "\n",
    "        # Для отладки рисуем объекты, входящие в нужные классы\n",
    "        if classes[class_index] in classes_to_look_for:\n",
    "            objects_count += 1\n",
    "            image_to_process = draw_object_bounding_box(image_to_process,\n",
    "                                                        class_index, box)\n",
    "\n",
    "    final_image = draw_object_count(image_to_process, objects_count)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_object_bounding_box(image_to_process, index, box):\n",
    "    \"\"\"\n",
    "    Рисование границ объекта с надписями\n",
    "    :param image_to_process: исходное изображение\n",
    "    :param index: индекс класса объекта, определенного с помощью YOLO\n",
    "    :param box: координаты области вокруг объекта\n",
    "    :return: изображение с отмеченными объектами\n",
    "    \"\"\"\n",
    "\n",
    "    x, y, w, h = box\n",
    "    start = (x, y)\n",
    "    end = (x + w, y + h)\n",
    "    color = (0, 255, 0)\n",
    "    width = 2\n",
    "    final_image = cv2.rectangle(image_to_process, start, end, color, width)\n",
    "\n",
    "    start = (x, y - 10)\n",
    "    font_size = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 2\n",
    "    text = classes[index]\n",
    "    final_image = cv2.putText(final_image, text, start, font,\n",
    "                              font_size, color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_object_count(image_to_process, objects_count):\n",
    "    \"\"\"\n",
    "    Подпись количества найденных объектов на изображении\n",
    "    :param image_to_process: исходное изображение\n",
    "    :param objects_count: количество объектов нужного класса\n",
    "    :return: изображение с указанием количества найденных объектов\n",
    "    \"\"\"\n",
    "\n",
    "    start = (10, 120)\n",
    "    font_size = 1.5\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    width = 3\n",
    "    text = \"Objects found: \" + str(objects_count)\n",
    "\n",
    "    white_color = (255, 255, 255)\n",
    "    black_outline_color = (0, 0, 0)\n",
    "    final_image = cv2.putText(image_to_process, text, start, font, font_size,\n",
    "                              black_outline_color, width * 3, cv2.LINE_AA)\n",
    "    final_image = cv2.putText(final_image, text, start, font, font_size,\n",
    "                              white_color, width, cv2.LINE_AA)\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video_object_detection(video: str):\n",
    "    \"\"\"\n",
    "    Захват и анализ видео в реальном времени\n",
    "    \"\"\"\n",
    "    \n",
    "    ans = True\n",
    "    while ans:\n",
    "        try:\n",
    "            # Захват изображения из видео\n",
    "            video_camera_capture = cv2.VideoCapture(video) # Класс для захвата видео из видеофайлов, последовательностей изображений или камер\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "            out = cv2.VideoWriter(\"C:/Users/kizue/Downloads/output_video.webm\", fourcc, 20.0, (640, 360))\n",
    "            \n",
    "            while video_camera_capture.isOpened():\n",
    "                ret, frame = video_camera_capture.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Применение методов распознавания объектов YOLO\n",
    "                frame = apply_yolo_object_detection(frame)\n",
    "                \n",
    "                # Отображение обработанного изображения на экране с уменьшенным размером окна\n",
    "                frame = cv2.resize(frame, (1920 // 2, 1080 // 2))\n",
    "                cv2.imshow(\"Video Capture\", frame)\n",
    "                \n",
    "                out.write(frame)\n",
    "                \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            video_camera_capture.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            ans = False\n",
    "    \n",
    "        except KeyboardInterrupt:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    net = cv2.dnn.readNetFromDarknet(\"C:/Users/kizue/Downloads/yolov4-tiny.cfg\",\n",
    "                                     \"C:/Users/kizue/Downloads/yolov4-tiny.weights\")\n",
    "    layer_names = net.getLayerNames()\n",
    "    out_layers_indexes = net.getUnconnectedOutLayers()\n",
    "    out_layers = [layer_names[index - 1] for index in out_layers_indexes]\n",
    "\n",
    "    with open(\"C:/Users/kizue/Downloads/coco.names.txt\") as file:\n",
    "        classes = file.read().split(\"\\n\")\n",
    "\n",
    "    video = 'C:/Users/kizue/Downloads/segment_1.webm'\n",
    "    #video = 'C:/Users/kizue/Downloads/segment_8.webm'\n",
    "    #video = 'C:/Users/kizue/Downloads/segment_82.webm'\n",
    "    look_for = ['person']\n",
    "    \n",
    "    list_look_for = []\n",
    "    for look in look_for:\n",
    "        list_look_for.append(look.strip())\n",
    "\n",
    "    classes_to_look_for = list_look_for\n",
    "\n",
    "    start_video_object_detection(video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
